[ Skip to content ](https://ai.pydantic.dev/graph/#graphs)
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/ "PydanticAI")
PydanticAI 
Graphs 
Type to start searching
[ pydantic/pydantic-ai  ](https://github.com/pydantic/pydantic-ai "Go to repository")
[ ![logo](https://ai.pydantic.dev/img/logo-white.svg) ](https://ai.pydantic.dev/ "PydanticAI") PydanticAI 
[ pydantic/pydantic-ai  ](https://github.com/pydantic/pydantic-ai "Go to repository")
  * [ Introduction  ](https://ai.pydantic.dev/)
  * [ Installation  ](https://ai.pydantic.dev/install/)
  * [ Getting Help  ](https://ai.pydantic.dev/help/)
  * [ Contributing  ](https://ai.pydantic.dev/contributing/)
  * [ Troubleshooting  ](https://ai.pydantic.dev/troubleshooting/)
  * Documentation  Documentation 
    * [ Agents  ](https://ai.pydantic.dev/agents/)
    * [ Models  ](https://ai.pydantic.dev/models/)
    * [ Dependencies  ](https://ai.pydantic.dev/dependencies/)
    * [ Function Tools  ](https://ai.pydantic.dev/tools/)
    * [ Common Tools  ](https://ai.pydantic.dev/common_tools/)
    * [ Results  ](https://ai.pydantic.dev/results/)
    * [ Messages and chat history  ](https://ai.pydantic.dev/message-history/)
    * [ Testing and Evals  ](https://ai.pydantic.dev/testing-evals/)
    * [ Debugging and Monitoring  ](https://ai.pydantic.dev/logfire/)
    * [ Multi-agent Applications  ](https://ai.pydantic.dev/multi-agent-applications/)
    * Graphs  [ Graphs  ](https://ai.pydantic.dev/graph/) Table of contents 
      * [ Installation  ](https://ai.pydantic.dev/graph/#installation)
      * [ Graph Types  ](https://ai.pydantic.dev/graph/#graph-types)
        * [ GraphRunContext  ](https://ai.pydantic.dev/graph/#graphruncontext)
        * [ End  ](https://ai.pydantic.dev/graph/#end)
        * [ Nodes  ](https://ai.pydantic.dev/graph/#nodes)
        * [ Graph  ](https://ai.pydantic.dev/graph/#graph)
      * [ Stateful Graphs  ](https://ai.pydantic.dev/graph/#stateful-graphs)
      * [ GenAI Example  ](https://ai.pydantic.dev/graph/#genai-example)
      * [ Iterating Over a Graph  ](https://ai.pydantic.dev/graph/#iterating-over-a-graph)
        * [ Using Graph.iter for async for iteration  ](https://ai.pydantic.dev/graph/#using-graphiter-for-async-for-iteration)
        * [ Using GraphRun.next(node) manually  ](https://ai.pydantic.dev/graph/#using-graphrunnextnode-manually)
      * [ State Persistence  ](https://ai.pydantic.dev/graph/#state-persistence)
        * [ Example: Human in the loop.  ](https://ai.pydantic.dev/graph/#example-human-in-the-loop)
      * [ Dependency Injection  ](https://ai.pydantic.dev/graph/#dependency-injection)
      * [ Mermaid Diagrams  ](https://ai.pydantic.dev/graph/#mermaid-diagrams)
        * [ Setting Direction of the State Diagram  ](https://ai.pydantic.dev/graph/#setting-direction-of-the-state-diagram)
    * [ Image, Audio & Document Input  ](https://ai.pydantic.dev/input/)
    * [ Command Line Interface (CLI)  ](https://ai.pydantic.dev/cli/)
  * [ Examples  ](https://ai.pydantic.dev/examples/)
Examples 
    * [ Pydantic Model  ](https://ai.pydantic.dev/examples/pydantic-model/)
    * [ Weather agent  ](https://ai.pydantic.dev/examples/weather-agent/)
    * [ Bank support  ](https://ai.pydantic.dev/examples/bank-support/)
    * [ SQL Generation  ](https://ai.pydantic.dev/examples/sql-gen/)
    * [ Flight booking  ](https://ai.pydantic.dev/examples/flight-booking/)
    * [ RAG  ](https://ai.pydantic.dev/examples/rag/)
    * [ Stream markdown  ](https://ai.pydantic.dev/examples/stream-markdown/)
    * [ Stream whales  ](https://ai.pydantic.dev/examples/stream-whales/)
    * [ Chat App with FastAPI  ](https://ai.pydantic.dev/examples/chat-app/)
    * [ Question Graph  ](https://ai.pydantic.dev/examples/question-graph/)
  * API Reference  API Reference 
    * [ pydantic_ai.agent  ](https://ai.pydantic.dev/api/agent/)
    * [ pydantic_ai.tools  ](https://ai.pydantic.dev/api/tools/)
    * [ pydantic_ai.common_tools  ](https://ai.pydantic.dev/api/common_tools/)
    * [ pydantic_ai.result  ](https://ai.pydantic.dev/api/result/)
    * [ pydantic_ai.messages  ](https://ai.pydantic.dev/api/messages/)
    * [ pydantic_ai.exceptions  ](https://ai.pydantic.dev/api/exceptions/)
    * [ pydantic_ai.settings  ](https://ai.pydantic.dev/api/settings/)
    * [ pydantic_ai.usage  ](https://ai.pydantic.dev/api/usage/)
    * [ pydantic_ai.format_as_xml  ](https://ai.pydantic.dev/api/format_as_xml/)
    * [ pydantic_ai.models  ](https://ai.pydantic.dev/api/models/base/)
    * [ pydantic_ai.models.openai  ](https://ai.pydantic.dev/api/models/openai/)
    * [ pydantic_ai.models.anthropic  ](https://ai.pydantic.dev/api/models/anthropic/)
    * [ pydantic_ai.models.bedrock  ](https://ai.pydantic.dev/api/models/bedrock/)
    * [ pydantic_ai.models.cohere  ](https://ai.pydantic.dev/api/models/cohere/)
    * [ pydantic_ai.models.gemini  ](https://ai.pydantic.dev/api/models/gemini/)
    * [ pydantic_ai.models.vertexai  ](https://ai.pydantic.dev/api/models/vertexai/)
    * [ pydantic_ai.models.groq  ](https://ai.pydantic.dev/api/models/groq/)
    * [ pydantic_ai.models.mistral  ](https://ai.pydantic.dev/api/models/mistral/)
    * [ pydantic_ai.models.test  ](https://ai.pydantic.dev/api/models/test/)
    * [ pydantic_ai.models.function  ](https://ai.pydantic.dev/api/models/function/)
    * [ pydantic_ai.models.fallback  ](https://ai.pydantic.dev/api/models/fallback/)
    * [ pydantic_ai.providers  ](https://ai.pydantic.dev/api/providers/)
    * [ pydantic_graph  ](https://ai.pydantic.dev/api/pydantic_graph/graph/)
    * [ pydantic_graph.nodes  ](https://ai.pydantic.dev/api/pydantic_graph/nodes/)
    * [ pydantic_graph.persistence  ](https://ai.pydantic.dev/api/pydantic_graph/persistence/)
    * [ pydantic_graph.mermaid  ](https://ai.pydantic.dev/api/pydantic_graph/mermaid/)
    * [ pydantic_graph.exceptions  ](https://ai.pydantic.dev/api/pydantic_graph/exceptions/)


Table of contents 
  * [ Installation  ](https://ai.pydantic.dev/graph/#installation)
  * [ Graph Types  ](https://ai.pydantic.dev/graph/#graph-types)
    * [ GraphRunContext  ](https://ai.pydantic.dev/graph/#graphruncontext)
    * [ End  ](https://ai.pydantic.dev/graph/#end)
    * [ Nodes  ](https://ai.pydantic.dev/graph/#nodes)
    * [ Graph  ](https://ai.pydantic.dev/graph/#graph)
  * [ Stateful Graphs  ](https://ai.pydantic.dev/graph/#stateful-graphs)
  * [ GenAI Example  ](https://ai.pydantic.dev/graph/#genai-example)
  * [ Iterating Over a Graph  ](https://ai.pydantic.dev/graph/#iterating-over-a-graph)
    * [ Using Graph.iter for async for iteration  ](https://ai.pydantic.dev/graph/#using-graphiter-for-async-for-iteration)
    * [ Using GraphRun.next(node) manually  ](https://ai.pydantic.dev/graph/#using-graphrunnextnode-manually)
  * [ State Persistence  ](https://ai.pydantic.dev/graph/#state-persistence)
    * [ Example: Human in the loop.  ](https://ai.pydantic.dev/graph/#example-human-in-the-loop)
  * [ Dependency Injection  ](https://ai.pydantic.dev/graph/#dependency-injection)
  * [ Mermaid Diagrams  ](https://ai.pydantic.dev/graph/#mermaid-diagrams)
    * [ Setting Direction of the State Diagram  ](https://ai.pydantic.dev/graph/#setting-direction-of-the-state-diagram)


# Graphs
Don't use a nail gun unless you need a nail gun
If PydanticAI [agents](https://ai.pydantic.dev/agents/) are a hammer, and [multi-agent workflows](https://ai.pydantic.dev/multi-agent-applications/) are a sledgehammer, then graphs are a nail gun:
  * sure, nail guns look cooler than hammers
  * but nail guns take a lot more setup than hammers
  * and nail guns don't make you a better builder, they make you a builder with a nail gun
  * Lastly, (and at the risk of torturing this metaphor), if you're a fan of medieval tools like mallets and untyped Python, you probably won't like nail guns or our approach to graphs. (But then again, if you're not a fan of type hints in Python, you've probably already bounced off PydanticAI to use one of the toy agent frameworks — good luck, and feel free to borrow my sledgehammer when you realize you need it)


In short, graphs are a powerful tool, but they're not the right tool for every job. Please consider other [multi-agent approaches](https://ai.pydantic.dev/multi-agent-applications/) before proceeding.
If you're not confident a graph-based approach is a good idea, it might be unnecessary.
Graphs and finite state machines (FSMs) are a powerful abstraction to model, execute, control and visualize complex workflows.
Alongside PydanticAI, we've developed `pydantic-graph` — an async graph and state machine library for Python where nodes and edges are defined using type hints.
While this library is developed as part of PydanticAI; it has no dependency on `pydantic-ai` and can be considered as a pure graph-based state machine library. You may find it useful whether or not you're using PydanticAI or even building with GenAI.
`pydantic-graph` is designed for advanced users and makes heavy use of Python generics and type hints. It is not designed to be as beginner-friendly as PydanticAI.
## Installation
`pydantic-graph` is a required dependency of `pydantic-ai`, and an optional dependency of `pydantic-ai-slim`, see [installation instructions](https://ai.pydantic.dev/install/#slim-install) for more information. You can also install it directly:
[pip](https://ai.pydantic.dev/graph/#__tabbed_1_1)[uv](https://ai.pydantic.dev/graph/#__tabbed_1_2)
```
pipinstallpydantic-graph

```

```
uvaddpydantic-graph

```

## Graph Types
`pydantic-graph` is made up of a few key components:
### GraphRunContext
[`GraphRunContext`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.GraphRunContext) — The context for the graph run, similar to PydanticAI's [`RunContext`](https://ai.pydantic.dev/api/tools/#pydantic_ai.tools.RunContext). This holds the state of the graph and dependencies and is passed to nodes when they're run.
`GraphRunContext` is generic in the state type of the graph it's used in, [`StateT`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.StateT).
### End
[`End`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.End) — return value to indicate the graph run should end.
`End` is generic in the graph return type of the graph it's used in, [`RunEndT`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.RunEndT).
### Nodes
Subclasses of [`BaseNode`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode) define nodes for execution in the graph.
Nodes, which are generally [`dataclass`es](https://docs.python.org/3/library/dataclasses.html#dataclasses.dataclass), generally consist of:
  * fields containing any parameters required/optional when calling the node
  * the business logic to execute the node, in the [`run`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode.run) method
  * return annotations of the [`run`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode.run) method, which are read by `pydantic-graph` to determine the outgoing edges of the node


Nodes are generic in:
  * **state** , which must have the same type as the state of graphs they're included in, [`StateT`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.StateT) has a default of `None`, so if you're not using state you can omit this generic parameter, see [stateful graphs](https://ai.pydantic.dev/graph/#stateful-graphs) for more information
  * **deps** , which must have the same type as the deps of the graph they're included in, [`DepsT`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.DepsT) has a default of `None`, so if you're not using deps you can omit this generic parameter, see [dependency injection](https://ai.pydantic.dev/graph/#dependency-injection) for more information
  * **graph return type** — this only applies if the node returns [`End`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.End). [`RunEndT`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.RunEndT) has a default of [Never](https://docs.python.org/3/library/typing.html#typing.Never) so this generic parameter can be omitted if the node doesn't return `End`, but must be included if it does.


Here's an example of a start or intermediate node in a graph — it can't end the run as it doesn't return [`End`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.End):
intermediate_node.py```
fromdataclassesimport dataclass
frompydantic_graphimport BaseNode, GraphRunContext

@dataclass
classMyNode(BaseNode[MyState]): [](https://ai.pydantic.dev/graph/#__code_2_annotation_1)
  foo: int [](https://ai.pydantic.dev/graph/#__code_2_annotation_2)
  async defrun(
    self,
    ctx: GraphRunContext[MyState], [](https://ai.pydantic.dev/graph/#__code_2_annotation_3)
  ) -> AnotherNode: [](https://ai.pydantic.dev/graph/#__code_2_annotation_4)
    ...
    return AnotherNode()

```

We could extend `MyNode` to optionally end the run if `foo` is divisible by 5:
intermediate_or_end_node.py```
fromdataclassesimport dataclass
frompydantic_graphimport BaseNode, End, GraphRunContext

@dataclass
classMyNode(BaseNode[MyState, None, int]): [](https://ai.pydantic.dev/graph/#__code_3_annotation_1)
  foo: int
  async defrun(
    self,
    ctx: GraphRunContext[MyState],
  ) -> AnotherNode | End[int]: [](https://ai.pydantic.dev/graph/#__code_3_annotation_2)
    if self.foo % 5 == 0:
      return End(self.foo)
    else:
      return AnotherNode()

```

### Graph
[`Graph`](https://ai.pydantic.dev/api/pydantic_graph/graph/#pydantic_graph.graph.Graph) — this is the execution graph itself, made up of a set of [node classes](https://ai.pydantic.dev/graph/#nodes) (i.e., `BaseNode` subclasses).
`Graph` is generic in:
  * **state** the state type of the graph, [`StateT`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.StateT)
  * **deps** the deps type of the graph, [`DepsT`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.DepsT)
  * **graph return type** the return type of the graph run, [`RunEndT`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.RunEndT)


Here's an example of a simple graph:
graph_example.py```
from__future__import annotations
fromdataclassesimport dataclass
frompydantic_graphimport BaseNode, End, Graph, GraphRunContext

@dataclass
classDivisibleBy5(BaseNode[None, None, int]): [](https://ai.pydantic.dev/graph/#__code_4_annotation_1)
  foo: int
  async defrun(
    self,
    ctx: GraphRunContext,
  ) -> Increment | End[int]:
    if self.foo % 5 == 0:
      return End(self.foo)
    else:
      return Increment(self.foo)

@dataclass
classIncrement(BaseNode): [](https://ai.pydantic.dev/graph/#__code_4_annotation_2)
  foo: int
  async defrun(self, ctx: GraphRunContext) -> DivisibleBy5:
    return DivisibleBy5(self.foo + 1)

fives_graph = Graph(nodes=[DivisibleBy5, Increment]) [](https://ai.pydantic.dev/graph/#__code_4_annotation_3)
result = fives_graph.run_sync(DivisibleBy5(4)) [](https://ai.pydantic.dev/graph/#__code_4_annotation_4)
print(result.output)
#> 5

```

_(This example is complete, it can be run "as is" with Python 3.10+)_
A [mermaid diagram](https://ai.pydantic.dev/graph/#mermaid-diagrams) for this graph can be generated with the following code:
graph_example_diagram.py```
fromgraph_exampleimport DivisibleBy5, fives_graph
fives_graph.mermaid_code(start_node=DivisibleBy5)

```

In order to visualize a graph within a `jupyter-notebook`, `IPython.display` needs to be used:
jupyter_display_mermaid.py```
fromgraph_exampleimport DivisibleBy5, fives_graph
fromIPython.displayimport Image, display
display(Image(fives_graph.mermaid_image(start_node=DivisibleBy5)))

```

## Stateful Graphs
The "state" concept in `pydantic-graph` provides an optional way to access and mutate an object (often a `dataclass` or Pydantic model) as nodes run in a graph. If you think of Graphs as a production line, then your state is the engine being passed along the line and built up by each node as the graph is run.
In the future, we intend to extend `pydantic-graph` to provide state persistence with the state recorded after each node is run, see [#695](https://github.com/pydantic/pydantic-ai/issues/695).
Here's an example of a graph which represents a vending machine where the user may insert coins and select a product to purchase.
vending_machine.py```
from__future__import annotations
fromdataclassesimport dataclass
fromrich.promptimport Prompt
frompydantic_graphimport BaseNode, End, Graph, GraphRunContext

@dataclass
classMachineState: [](https://ai.pydantic.dev/graph/#__code_7_annotation_1)
  user_balance: float = 0.0
  product: str | None = None

@dataclass
classInsertCoin(BaseNode[MachineState]): [](https://ai.pydantic.dev/graph/#__code_7_annotation_3)
  async defrun(self, ctx: GraphRunContext[MachineState]) -> CoinsInserted: [](https://ai.pydantic.dev/graph/#__code_7_annotation_16)
    return CoinsInserted(float(Prompt.ask('Insert coins'))) [](https://ai.pydantic.dev/graph/#__code_7_annotation_4)

@dataclass
classCoinsInserted(BaseNode[MachineState]):
  amount: float [](https://ai.pydantic.dev/graph/#__code_7_annotation_5)
  async defrun(
    self, ctx: GraphRunContext[MachineState]
  ) -> SelectProduct | Purchase: [](https://ai.pydantic.dev/graph/#__code_7_annotation_17)
    ctx.state.user_balance += self.amount [](https://ai.pydantic.dev/graph/#__code_7_annotation_6)
    if ctx.state.product is not None: [](https://ai.pydantic.dev/graph/#__code_7_annotation_7)
      return Purchase(ctx.state.product)
    else:
      return SelectProduct()

@dataclass
classSelectProduct(BaseNode[MachineState]):
  async defrun(self, ctx: GraphRunContext[MachineState]) -> Purchase:
    return Purchase(Prompt.ask('Select product'))

PRODUCT_PRICES = { [](https://ai.pydantic.dev/graph/#__code_7_annotation_2)
  'water': 1.25,
  'soda': 1.50,
  'crisps': 1.75,
  'chocolate': 2.00,
}

@dataclass
classPurchase(BaseNode[MachineState, None, None]): [](https://ai.pydantic.dev/graph/#__code_7_annotation_18)
  product: str
  async defrun(
    self, ctx: GraphRunContext[MachineState]
  ) -> End | InsertCoin | SelectProduct:
    if price := PRODUCT_PRICES.get(self.product): [](https://ai.pydantic.dev/graph/#__code_7_annotation_8)
      ctx.state.product = self.product [](https://ai.pydantic.dev/graph/#__code_7_annotation_9)
      if ctx.state.user_balance >= price: [](https://ai.pydantic.dev/graph/#__code_7_annotation_10)
        ctx.state.user_balance -= price
        return End(None)
      else:
        diff = price - ctx.state.user_balance
        print(f'Not enough money for {self.product}, need {diff:0.2f} more')
        #> Not enough money for crisps, need 0.75 more
        return InsertCoin() [](https://ai.pydantic.dev/graph/#__code_7_annotation_11)
    else:
      print(f'No such product: {self.product}, try again')
      return SelectProduct() [](https://ai.pydantic.dev/graph/#__code_7_annotation_12)

vending_machine_graph = Graph( [](https://ai.pydantic.dev/graph/#__code_7_annotation_13)
  nodes=[InsertCoin, CoinsInserted, SelectProduct, Purchase]
)

async defmain():
  state = MachineState() [](https://ai.pydantic.dev/graph/#__code_7_annotation_14)
  await vending_machine_graph.run(InsertCoin(), state=state) [](https://ai.pydantic.dev/graph/#__code_7_annotation_15)
  print(f'purchase successful item={state.product} change={state.user_balance:0.2f}')
  #> purchase successful item=crisps change=0.25

```

_(This example is complete, it can be run "as is" with Python 3.10+ — you'll need to add`asyncio.run(main())` to run `main`)_
A [mermaid diagram](https://ai.pydantic.dev/graph/#mermaid-diagrams) for this graph can be generated with the following code:
vending_machine_diagram.py```
fromvending_machineimport InsertCoin, vending_machine_graph
vending_machine_graph.mermaid_code(start_node=InsertCoin)

```

The diagram generated by the above code is:
See [below](https://ai.pydantic.dev/graph/#mermaid-diagrams) for more information on generating diagrams.
## GenAI Example
So far we haven't shown an example of a Graph that actually uses PydanticAI or GenAI at all.
In this example, one agent generates a welcome email to a user and the other agent provides feedback on the email.
This graph has a very simple structure:
genai_email_feedback.py```
from__future__import annotations as _annotations
fromdataclassesimport dataclass, field
frompydanticimport BaseModel, EmailStr
frompydantic_aiimport Agent
frompydantic_ai.format_as_xmlimport format_as_xml
frompydantic_ai.messagesimport ModelMessage
frompydantic_graphimport BaseNode, End, Graph, GraphRunContext

@dataclass
classUser:
  name: str
  email: EmailStr
  interests: list[str]

@dataclass
classEmail:
  subject: str
  body: str

@dataclass
classState:
  user: User
  write_agent_messages: list[ModelMessage] = field(default_factory=list)

email_writer_agent = Agent(
  'google-vertex:gemini-1.5-pro',
  result_type=Email,
  system_prompt='Write a welcome email to our tech blog.',
)

@dataclass
classWriteEmail(BaseNode[State]):
  email_feedback: str | None = None
  async defrun(self, ctx: GraphRunContext[State]) -> Feedback:
    if self.email_feedback:
      prompt = (
        f'Rewrite the email for the user:\n'
        f'{format_as_xml(ctx.state.user)}\n'
        f'Feedback: {self.email_feedback}'
      )
    else:
      prompt = (
        f'Write a welcome email for the user:\n'
        f'{format_as_xml(ctx.state.user)}'
      )
    result = await email_writer_agent.run(
      prompt,
      message_history=ctx.state.write_agent_messages,
    )
    ctx.state.write_agent_messages += result.all_messages()
    return Feedback(result.data)

classEmailRequiresWrite(BaseModel):
  feedback: str

classEmailOk(BaseModel):
  pass

feedback_agent = Agent[None, EmailRequiresWrite | EmailOk](
  'openai:gpt-4o',
  result_type=EmailRequiresWrite | EmailOk, # type: ignore
  system_prompt=(
    'Review the email and provide feedback, email must reference the users specific interests.'
  ),
)

@dataclass
classFeedback(BaseNode[State, None, Email]):
  email: Email
  async defrun(
    self,
    ctx: GraphRunContext[State],
  ) -> WriteEmail | End[Email]:
    prompt = format_as_xml({'user': ctx.state.user, 'email': self.email})
    result = await feedback_agent.run(prompt)
    if isinstance(result.data, EmailRequiresWrite):
      return WriteEmail(email_feedback=result.data.feedback)
    else:
      return End(self.email)

async defmain():
  user = User(
    name='John Doe',
    email='john.joe@example.com',
    interests=['Haskel', 'Lisp', 'Fortran'],
  )
  state = State(user)
  feedback_graph = Graph(nodes=(WriteEmail, Feedback))
  result = await feedback_graph.run(WriteEmail(), state=state)
  print(result.output)
"""
  Email(
    subject='Welcome to our tech blog!',
    body='Hello John, Welcome to our tech blog! ...',
  )
  """

```

_(This example is complete, it can be run "as is" with Python 3.10+ — you'll need to add`asyncio.run(main())` to run `main`)_
## Iterating Over a Graph
### Using `Graph.iter` for `async for` iteration
Sometimes you want direct control or insight into each node as the graph executes. The easiest way to do that is with the [`Graph.iter`](https://ai.pydantic.dev/api/pydantic_graph/graph/#pydantic_graph.graph.Graph.iter) method, which returns a **context manager** that yields a [`GraphRun`](https://ai.pydantic.dev/api/pydantic_graph/graph/#pydantic_graph.graph.GraphRun) object. The `GraphRun` is an async-iterable over the nodes of your graph, allowing you to record or modify them as they execute.
Here's an example:
count_down.py```
from__future__import annotations as _annotations
fromdataclassesimport dataclass
frompydantic_graphimport Graph, BaseNode, End, GraphRunContext

@dataclass
classCountDownState:
  counter: int

@dataclass
classCountDown(BaseNode[CountDownState, None, int]):
  async defrun(self, ctx: GraphRunContext[CountDownState]) -> CountDown | End[int]:
    if ctx.state.counter <= 0:
      return End(ctx.state.counter)
    ctx.state.counter -= 1
    return CountDown()

count_down_graph = Graph(nodes=[CountDown])

async defmain():
  state = CountDownState(counter=3)
  async with count_down_graph.iter(CountDown(), state=state) as run: [](https://ai.pydantic.dev/graph/#__code_10_annotation_1)
    async for node in run: [](https://ai.pydantic.dev/graph/#__code_10_annotation_2)
      print('Node:', node)
      #> Node: CountDown()
      #> Node: CountDown()
      #> Node: CountDown()
      #> Node: End(data=0)
  print('Final result:', run.result.output) [](https://ai.pydantic.dev/graph/#__code_10_annotation_3)
  #> Final result: 0

```

### Using `GraphRun.next(node)` manually
Alternatively, you can drive iteration manually with the [`GraphRun.next`](https://ai.pydantic.dev/api/pydantic_graph/graph/#pydantic_graph.graph.GraphRun.next) method, which allows you to pass in whichever node you want to run next. You can modify or selectively skip nodes this way.
Below is a contrived example that stops whenever the counter is at 2, ignoring any node runs beyond that:
count_down_next.py```
frompydantic_graphimport End, FullStatePersistence
fromcount_downimport CountDown, CountDownState, count_down_graph

async defmain():
  state = CountDownState(counter=5)
  persistence = FullStatePersistence() [](https://ai.pydantic.dev/graph/#__code_11_annotation_7)
  async with count_down_graph.iter(
    CountDown(), state=state, persistence=persistence
  ) as run:
    node = run.next_node [](https://ai.pydantic.dev/graph/#__code_11_annotation_1)
    while not isinstance(node, End): [](https://ai.pydantic.dev/graph/#__code_11_annotation_2)
      print('Node:', node)
      #> Node: CountDown()
      #> Node: CountDown()
      #> Node: CountDown()
      #> Node: CountDown()
      if state.counter == 2:
        break [](https://ai.pydantic.dev/graph/#__code_11_annotation_3)
      node = await run.next(node) [](https://ai.pydantic.dev/graph/#__code_11_annotation_4)
    print(run.result) [](https://ai.pydantic.dev/graph/#__code_11_annotation_5)
    #> None
    for step in persistence.history: [](https://ai.pydantic.dev/graph/#__code_11_annotation_6)
      print('History Step:', step.state, step.state)
      #> History Step: CountDownState(counter=5) CountDownState(counter=5)
      #> History Step: CountDownState(counter=4) CountDownState(counter=4)
      #> History Step: CountDownState(counter=3) CountDownState(counter=3)
      #> History Step: CountDownState(counter=2) CountDownState(counter=2)

```

## State Persistence
One of the biggest benefits of finite state machine (FSM) graphs is how they simplify the handling of interrupted execution. This might happen for a variety of reasons:
  * the state machine logic might fundamentally need to be paused — e.g. the returns workflow for an e-commerce order needs to wait for the item to be posted to the returns center or because execution of the next node needs input from a user so needs to wait for a new http request,
  * the execution takes so long that the entire graph can't reliably be executed in a single continuous run — e.g. a deep research agent that might take hours to run,
  * you want to run multiple graph nodes in parallel in different processes / hardware instances (note: parallel node execution is not yet supported in `pydantic-graph`, see [#704](https://github.com/pydantic/pydantic-ai/issues/704)).


Trying to make a conventional control flow (i.e., boolean logic and nested function calls) implementation compatible with these usage scenarios generally results in brittle and over-complicated spaghetti code, with the logic required to interrupt and resume execution dominating the implementation.
To allow graph runs to be interrupted and resumed, `pydantic-graph` provides state persistence — a system for snapshotting the state of a graph run before and after each node is run, allowing a graph run to be resumed from any point in the graph.
`pydantic-graph` includes three state persistence implementations:
  * [`SimpleStatePersistence`](https://ai.pydantic.dev/api/pydantic_graph/persistence/#pydantic_graph.persistence.in_mem.SimpleStatePersistence) — Simple in memory state persistence that just hold the latest snapshot. If no state persistence implementation is provided when running a graph, this is used by default.
  * [`FullStatePersistence`](https://ai.pydantic.dev/api/pydantic_graph/persistence/#pydantic_graph.persistence.in_mem.FullStatePersistence) — In memory state persistence that hold a list of snapshots.
  * [`FileStatePersistence`](https://ai.pydantic.dev/api/pydantic_graph/persistence/#pydantic_graph.persistence.file.FileStatePersistence) — File-based state persistence that saves snapshots to a JSON file.


In production applications, developers should implement their own state persistence by subclassing [`BaseStatePersistence`](https://ai.pydantic.dev/api/pydantic_graph/persistence/#pydantic_graph.persistence.BaseStatePersistence) abstract base class, which might persist runs in a relational database like PostgresQL.
At a high level the role of `StatePersistence` implementations is to store and retrieve [`NodeSnapshot`](https://ai.pydantic.dev/api/pydantic_graph/persistence/#pydantic_graph.persistence.NodeSnapshot) and [`EndSnapshot`](https://ai.pydantic.dev/api/pydantic_graph/persistence/#pydantic_graph.persistence.EndSnapshot) objects.
[`graph.iter_from_persistence()`](https://ai.pydantic.dev/api/pydantic_graph/graph/#pydantic_graph.graph.Graph.iter_from_persistence) may be used to run the graph based on the state stored in persistence.
We can run the `count_down_graph` from [above](https://ai.pydantic.dev/graph/#iterating-over-a-graph), using [`graph.iter_from_persistence()`](https://ai.pydantic.dev/api/pydantic_graph/graph/#pydantic_graph.graph.Graph.iter_from_persistence) and [`FileStatePersistence`](https://ai.pydantic.dev/api/pydantic_graph/persistence/#pydantic_graph.persistence.file.FileStatePersistence).
As you can see in this code, `run_node` requires no external application state (apart from state persistence) to be run, meaning graphs can easily be executed by distributed execution and queueing systems.
count_down_from_persistence.py```
frompathlibimport Path
frompydantic_graphimport End
frompydantic_graph.persistence.fileimport FileStatePersistence
fromcount_downimport CountDown, CountDownState, count_down_graph

async defmain():
  run_id = 'run_abc123'
  persistence = FileStatePersistence(Path(f'count_down_{run_id}.json')) [](https://ai.pydantic.dev/graph/#__code_12_annotation_1)
  state = CountDownState(counter=5)
  await count_down_graph.initialize( [](https://ai.pydantic.dev/graph/#__code_12_annotation_2)
    CountDown(), state=state, persistence=persistence
  )
  done = False
  while not done:
    done = await run_node(run_id)

async defrun_node(run_id: str) -> bool: [](https://ai.pydantic.dev/graph/#__code_12_annotation_3)
  persistence = FileStatePersistence(Path(f'count_down_{run_id}.json'))
  async with count_down_graph.iter_from_persistence(persistence) as run: [](https://ai.pydantic.dev/graph/#__code_12_annotation_4)
    node_or_end = await run.next() [](https://ai.pydantic.dev/graph/#__code_12_annotation_5)
  print('Node:', node_or_end)
  #> Node: CountDown()
  #> Node: CountDown()
  #> Node: CountDown()
  #> Node: CountDown()
  #> Node: CountDown()
  #> Node: End(data=0)
  return isinstance(node_or_end, End) [](https://ai.pydantic.dev/graph/#__code_12_annotation_6)

```

_(This example is complete, it can be run "as is" with Python 3.10+ — you'll need to add`asyncio.run(main())` to run `main`)_
### Example: Human in the loop.
As noted above, state persistence allows graphs to be interrupted and resumed. One use case of this is to allow user input to continue.
In this example, an AI asks the user a question, the user provides an answer, the AI evaluates the answer and ends if the user got it right or asks another question if they got it wrong.
Instead of running the entire graph in a single process invocation, we run the graph by running the process repeatedly, optionally providing an answer to the question as a command line argument.
`ai_q_and_a_graph.py` — `question_graph` definition
ai_q_and_a_graph.py```
from__future__import annotations as _annotations
fromdataclassesimport dataclass, field
fromgroqimport BaseModel
frompydantic_graphimport (
  BaseNode,
  End,
  Graph,
  GraphRunContext,
)
frompydantic_aiimport Agent
frompydantic_ai.format_as_xmlimport format_as_xml
frompydantic_ai.messagesimport ModelMessage
ask_agent = Agent('openai:gpt-4o', result_type=str, instrument=True)

@dataclass
classQuestionState:
  question: str | None = None
  ask_agent_messages: list[ModelMessage] = field(default_factory=list)
  evaluate_agent_messages: list[ModelMessage] = field(default_factory=list)

@dataclass
classAsk(BaseNode[QuestionState]):
  async defrun(self, ctx: GraphRunContext[QuestionState]) -> Answer:
    result = await ask_agent.run(
      'Ask a simple question with a single correct answer.',
      message_history=ctx.state.ask_agent_messages,
    )
    ctx.state.ask_agent_messages += result.all_messages()
    ctx.state.question = result.data
    return Answer(result.data)

@dataclass
classAnswer(BaseNode[QuestionState]):
  question: str
  async defrun(self, ctx: GraphRunContext[QuestionState]) -> Evaluate:
    answer = input(f'{self.question}: ')
    return Evaluate(answer)

classEvaluationResult(BaseModel, use_attribute_docstrings=True):
  correct: bool
"""Whether the answer is correct."""
  comment: str
"""Comment on the answer, reprimand the user if the answer is wrong."""

evaluate_agent = Agent(
  'openai:gpt-4o',
  result_type=EvaluationResult,
  system_prompt='Given a question and answer, evaluate if the answer is correct.',
)

@dataclass
classEvaluate(BaseNode[QuestionState, None, str]):
  answer: str
  async defrun(
    self,
    ctx: GraphRunContext[QuestionState],
  ) -> End[str] | Reprimand:
    assert ctx.state.question is not None
    result = await evaluate_agent.run(
      format_as_xml({'question': ctx.state.question, 'answer': self.answer}),
      message_history=ctx.state.evaluate_agent_messages,
    )
    ctx.state.evaluate_agent_messages += result.all_messages()
    if result.data.correct:
      return End(result.data.comment)
    else:
      return Reprimand(result.data.comment)

@dataclass
classReprimand(BaseNode[QuestionState]):
  comment: str
  async defrun(self, ctx: GraphRunContext[QuestionState]) -> Ask:
    print(f'Comment: {self.comment}')
    ctx.state.question = None
    return Ask()

question_graph = Graph(
  nodes=(Ask, Answer, Evaluate, Reprimand), state_type=QuestionState
)

```

_(This example is complete, it can be run "as is" with Python 3.10+)_
ai_q_and_a_run.py```
importsys
frompathlibimport Path
frompydantic_graphimport End
frompydantic_graph.persistence.fileimport FileStatePersistence
frompydantic_ai.messagesimport ModelMessage # noqa: F401
fromai_q_and_a_graphimport Ask, question_graph, Evaluate, QuestionState, Answer

async defmain():
  answer: str | None = sys.argv[2] if len(sys.argv) > 2 else None [](https://ai.pydantic.dev/graph/#__code_14_annotation_1)
  persistence = FileStatePersistence(Path('question_graph.json')) [](https://ai.pydantic.dev/graph/#__code_14_annotation_2)
  persistence.set_graph_types(question_graph) [](https://ai.pydantic.dev/graph/#__code_14_annotation_3)
  if snapshot := await persistence.load_next(): [](https://ai.pydantic.dev/graph/#__code_14_annotation_4)
    state = snapshot.state
    assert answer is not None
    node = Evaluate(answer)
  else:
    state = QuestionState()
    node = Ask() [](https://ai.pydantic.dev/graph/#__code_14_annotation_5)
  async with question_graph.iter(node, state=state, persistence=persistence) as run:
    while True:
      node = await run.next() [](https://ai.pydantic.dev/graph/#__code_14_annotation_6)
      if isinstance(node, End): [](https://ai.pydantic.dev/graph/#__code_14_annotation_7)
        print('END:', node.data)
        history = await persistence.load_all() [](https://ai.pydantic.dev/graph/#__code_14_annotation_8)
        print([e.node for e in history])
        break
      elif isinstance(node, Answer): [](https://ai.pydantic.dev/graph/#__code_14_annotation_9)
        print(node.question)
        #> What is the capital of France?
        break
      # otherwise just continue

```

_(This example is complete, it can be run "as is" with Python 3.10+ — you'll need to add`asyncio.run(main(answer))` to run `main`)_
For a complete example of this graph, see the [question graph example](https://ai.pydantic.dev/examples/question-graph/).
## Dependency Injection
As with PydanticAI, `pydantic-graph` supports dependency injection via a generic parameter on [`Graph`](https://ai.pydantic.dev/api/pydantic_graph/graph/#pydantic_graph.graph.Graph) and [`BaseNode`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode), and the [`GraphRunContext.deps`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.GraphRunContext.deps) field.
As an example of dependency injection, let's modify the `DivisibleBy5` example [above](https://ai.pydantic.dev/graph/#graph) to use a [`ProcessPoolExecutor`](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor) to run the compute load in a separate process (this is a contrived example, `ProcessPoolExecutor` wouldn't actually improve performance in this example):
deps_example.py```
from__future__import annotations
importasyncio
fromconcurrent.futuresimport ProcessPoolExecutor
fromdataclassesimport dataclass
frompydantic_graphimport BaseNode, End, Graph, GraphRunContext

@dataclass
classGraphDeps:
  executor: ProcessPoolExecutor

@dataclass
classDivisibleBy5(BaseNode[None, GraphDeps, int]):
  foo: int
  async defrun(
    self,
    ctx: GraphRunContext[None, GraphDeps],
  ) -> Increment | End[int]:
    if self.foo % 5 == 0:
      return End(self.foo)
    else:
      return Increment(self.foo)

@dataclass
classIncrement(BaseNode[None, GraphDeps]):
  foo: int
  async defrun(self, ctx: GraphRunContext[None, GraphDeps]) -> DivisibleBy5:
    loop = asyncio.get_running_loop()
    compute_result = await loop.run_in_executor(
      ctx.deps.executor,
      self.compute,
    )
    return DivisibleBy5(compute_result)
  defcompute(self) -> int:
    return self.foo + 1

fives_graph = Graph(nodes=[DivisibleBy5, Increment])

async defmain():
  with ProcessPoolExecutor() as executor:
    deps = GraphDeps(executor)
    result = await fives_graph.run(DivisibleBy5(3), deps=deps)
  print(result.output)
  #> 5
  # the full history is quite verbose (see below), so we'll just print the summary
  print([item.data_snapshot() for item in result.history])
"""
  [
    DivisibleBy5(foo=3),
    Increment(foo=3),
    DivisibleBy5(foo=4),
    Increment(foo=4),
    DivisibleBy5(foo=5),
    End(data=5),
  ]
  """

```

_(This example is complete, it can be run "as is" with Python 3.10+ — you'll need to add`asyncio.run(main())` to run `main`)_
## Mermaid Diagrams
Pydantic Graph can generate [mermaid](https://mermaid.js.org/) [`stateDiagram-v2`](https://mermaid.js.org/syntax/stateDiagram.html) diagrams for graphs, as shown above.
These diagrams can be generated with:
  * [`Graph.mermaid_code`](https://ai.pydantic.dev/api/pydantic_graph/graph/#pydantic_graph.graph.Graph.mermaid_code) to generate the mermaid code for a graph
  * [`Graph.mermaid_image`](https://ai.pydantic.dev/api/pydantic_graph/graph/#pydantic_graph.graph.Graph.mermaid_image) to generate an image of the graph using [mermaid.ink](https://mermaid.ink/)
  * [`Graph.mermaid_save`](https://ai.pydantic.dev/api/pydantic_graph/graph/#pydantic_graph.graph.Graph.mermaid_save) to generate an image of the graph using [mermaid.ink](https://mermaid.ink/) and save it to a file


Beyond the diagrams shown above, you can also customize mermaid diagrams with the following options:
  * [`Edge`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.Edge) allows you to apply a label to an edge
  * [`BaseNode.docstring_notes`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode.docstring_notes) and [`BaseNode.get_note`](https://ai.pydantic.dev/api/pydantic_graph/nodes/#pydantic_graph.nodes.BaseNode.get_note) allows you to add notes to nodes
  * The [`highlighted_nodes`](https://ai.pydantic.dev/api/pydantic_graph/graph/#pydantic_graph.graph.Graph.mermaid_code) parameter allows you to highlight specific node(s) in the diagram


Putting that together, we can edit the last [`ai_q_and_a_graph.py`](https://ai.pydantic.dev/graph/#example-human-in-the-loop) example to:
  * add labels to some edges
  * add a note to the `Ask` node
  * highlight the `Answer` node
  * save the diagram as a `PNG` image to file


ai_q_and_a_graph_extra.py```
...
fromtypingimport Annotated

frompydantic_graphimport BaseNode, End, Graph, GraphRunContext, Edge

...
@dataclass
classAsk(BaseNode[QuestionState]):
"""Generate question using GPT-4o."""
  docstring_notes = True
  async defrun(
    self, ctx: GraphRunContext[QuestionState]
  ) -> Annotated[Answer, Edge(label='Ask the question')]:
    ...
...
@dataclass
classEvaluate(BaseNode[QuestionState]):
  answer: str
  async defrun(
      self,
      ctx: GraphRunContext[QuestionState],
  ) -> Annotated[End[str], Edge(label='success')] | Reprimand:
    ...
...
question_graph.mermaid_save('image.png', highlighted_nodes=[Answer])

```

_(This example is not complete and cannot be run directly)_
This would generate an image that looks like this:
### Setting Direction of the State Diagram
You can specify the direction of the state diagram using one of the following values:
  * `'TB'`: Top to bottom, the diagram flows vertically from top to bottom.
  * `'LR'`: Left to right, the diagram flows horizontally from left to right.
  * `'RL'`: Right to left, the diagram flows horizontally from right to left.
  * `'BT'`: Bottom to top, the diagram flows vertically from bottom to top.


Here is an example of how to do this using 'Left to Right' (LR) instead of the default 'Top to Bottom' (TB): 
vending_machine_diagram.py```
fromvending_machineimport InsertCoin, vending_machine_graph
vending_machine_graph.mermaid_code(start_node=InsertCoin, direction='LR')

```

© Pydantic Services Inc. 2024 to present 
